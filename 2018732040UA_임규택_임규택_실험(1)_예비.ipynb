{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1oFF0X2uSP5schXX5HAxHkGMLRfE-NA0j","authorship_tag":"ABX9TyPPzBsUIbyBloK1qc0bjT3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0fEyvJ3p7Gkn"},"outputs":[],"source":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XuFqFYAy893U"}},{"cell_type":"markdown","source":["### 1. 머신러닝(Machine Learning)이란? \n","\n","기존에 우리가 컴퓨터를 통해 데이터들을 다루고 분류하여 결과를 산출해낼 때는, 인간이 직접 알고리즘을 만들어 데이터들을 다뤘습니다.\n","하지만 인간이 알고리즘을 만들어 주지 않아도,\n","기계가 데이터를 스스로 학습하여 알고리즘을 수정하는 방식이 머신러닝(Machine Learning)입니다.\n","예로 들어서, \"1 , 2 , 3 ,4 ,5 ,? , 7 ,8 \"라는 데이터가 있고 ?를 예측하는 문제가 있다고 가정해봅시다.\n","\n","우리는 ? 를 예측을 하기 위해서,\n","x 번째 오는 숫자를 y라 가정하고 y = x라는 함수(알고리즘)를 세워서 답이 문제를 해결하였습니다.\n","\n","여기서 인간이 직접 \" y = x \"라는 알고리즘을 세우지 않아도,\n","?를 제외한 1~8까지의 숫자(데이터)를 넣어주면,\n","기계가 알아서 학습하여 ? = 6이라는 결과를 도출해 내는 방식이 바로 머신러닝(Machine Learning)입니다.\n","\n","### 2. 머신러닝(Machine Learning)의 3가지 학습방식\n","\n","기계가 스스로 학습하는 방식인 머신러닝은 크게 3가지 종류로 나뉩니다.\n","\n","지도 학습 (Supervised Learning),\n","비지도 학습 (Unsupervised learning),\n","강화 학습(Reinforcement Learning)\n","\n","### 2-1. 지도 학습 (Supervised Learning)\n","\n","기계에게 정답인 강아지 사진을 입력하여 학습시킨 후,\n","\n","어떤 사진 x를 입력했을 때, 그것이 강아지 사진인지 아닌지를 판단하는 방법이 지도 학습 (Supervised Learning) 방법입니다.\n","\n","-> 지도 학습(Supervised Learning)에서 중요한 건,\n","\n","정답 데이터인 강아지 사진을 입력할 때, 강아지와 다른 동물들을 구별할 수 있는 명확한 특징(몸통의 길이, 다리의 개수 등등)이 정답 데이터를 입력해 줄 때, 명확하게 드러나야 합니다.\n","\n","### 2-2. 비지도 학습 (Unsupervised Learning)\n","\n","이와 달리 기계에게 학습시킬 때, 정답이 무엇인지 알려주지 않고 무작위의 고양이, 강아지 사진을 입력시킵니다.\n","\n","정답이 무엇인지는 모르지만,\n","기계는 입력받은 데이터들을 받아서 기계 스스로의 기준을 세우고, 각각의 사진들을 그룹화해서 고양이, 강아지 그룹으로 나누어 분류합니다.\n","\n","그 후, 어떤 사진 x를 입력하여 기계 스스로 이 사진이 강아지 그룹인지, 고양이 그룹인지를 분류하는 방식이\n","비지도 학습(UnSupervised Learning)입니다.\n","\n","----> 비지도 학습(Unsupervised learning)에서 중요한 건,\n","\n","정답 데이터를 주지 않기 때문에, 입력하는 데이터의 특징들이 지도학 습보다 더 명료해야 정확도 있는 학습이 가능하다는 것입니다.\n","\n","### 2-3. 강화 학습 (Reinforcement Learning)\n","\n","강화 학습(Reinforcement Learning)은  지도 학습, 비지도 학습 방식과는 완전히 다른 학습 방식입니다.\n","\n","상태(State), 행동(Action)이 존재하는 특정한 환경에서만 가능한 학습 방식으로써,\n","\n","행동(Action)에 따라 상태(State)가 변하고 그에 따라 주어지는 보상(Reward)을 통해 학습을 진행하는 방식입니다.\n","\n","\n","강화 학습을 이용한 대표적인 예시 \"알파고\"\n","\n","강화 학습을 쉽게 이해를 하기 위해, 강화 학습 방식이 쓰인 대표적인 프로그램인 알파고(AlpaGo)의 예시를 통해 이해해 봅시다.\n","\n","바둑이라는 놀이는,\n","바둑을 두는 행동(Action)과 행동(Action)마다 달라지는 바둑말들의 상황(State)이 존재하고, 마지막 결과에 따라 승패가 정해집니다. ( 즉 , 강화 학습을 활용할 수 있는 특수한 환경을 만족합니다.)\n","\n","여기서 승패에 따른 보상을 통해 알고리즘을 개선해 나아가며,\n","\n","말을 놓아야 하는 상태(State)마다 가장 승리에 가까운 최적의 행동(Action)을 하도록 학습해갑니다.\n","\n","---> 여기서 중요한 건, 각각의 상황마다 취한 행동이 즉각적으로 보상이 주어지지 않는 경우도 많기에,\n","\n","각각의 행동에 따른 보상을 어떻게 주어야 하냐는 점입니다. (바둑은 행동에 따른 결과가 마지막에 결정됨)\n","### [참조링크](https://strongai.tistory.com/3)\n","<https://strongai.tistory.com/3>"],"metadata":{"id":"_ppS9UF09jFz"}}]}